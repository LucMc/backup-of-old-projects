#import pandas as pd
import Quandl

df = Quandl.get("WIKI/GOOGL")

print(df.head())

'''
import pandas as pd
import quandl as Quandl
import math
import numpy as np
from sklearn import preprocessing, cross_validation, svm
from sklearn.linear_model import LinearRegression

df = Quandl.get('WIKI/GOOGL')
df = df[['Adj. Open','Adj. High','Adj. Low','Adj. Close','Adj. Volume']]
df['HL_PCT'] = (df['Adj. High'] - df['Adj. Close']) / df['Adj. Close'] * 100.0
df['PCT_change'] = (df['Adj. Close'] - df['Adj. Open']) / df['Adj. Open'] * 100.0

df = df[['Adj. Close', 'HL_PCT', 'PCT_change', 'Adj. Volume']]

forecast_col = 'Adj. Close'
df.fillna(-99999, inplace=True)

forecast_out = int(math.ceil(0.01*len(df)))#1% forecast

df['label'] = df[forecast_col].shift(-forecast_out)
df.dropna(inplace=True)

X = np.array(df.drop(['label'],1))#Feature, everything but the label collum
y = np.array(df['label'])#Label, the label colloumn
X = preprocessing.scale(X)

This makes it so the mean on the collums are the same so
that they all have the same ammount of influence on the algorthm
e.g. so small number changes ammoung small numbers = big changes
from big numbers

df.dropna(inplace=True)
y = np.array(df['label'])

X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)
clf = LinearRegression(n_jobs=-1)#or svm.SVR(kernel='poly') or svm.SVR()
#n_jobs is how many threads to use, -1 just does the most your system can do
clf.fit(X_train, y_train)
accuracy = clf.score(X_test,y_test)

print(df)
print(accuracy)
print(forecast_out)
'''